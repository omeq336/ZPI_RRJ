## Opis doświadczenia

Moje doświadczenie dotyczy realizacji innowacyjnego projektu stażowego w jednej z wiodących firm sektora kosmicznego. Zadaniem było stworzenie systemu służącego do automatycznej klasyfikacji i mapowania upraw na podstawie danych satelitarnych Sentinel-1 i Sentinel-2, z wykorzystaniem nowoczesnego modelu typu Foundation Model (opracowanego przez NASA Harvest). Było to moje pierwsze zetknięcie z tą specyficzną i zaawansowaną technologią

Projekt rozpocząłem od solidnego przygotowania merytorycznego. Przeprowadziłem research dostępnych rozwiązań, zapoznałem się z dokumentacją i przygotowałem środowisko pracy. Jednakże, ze względu na nowatorski charakter technologii, początkowo przyjąłem standardowe podejście do implementacji, które sprawdzało się w klasycznych modelach uczenia maszynowego. Skupiłem się na szybkim uruchomieniu prototypu, aby zweryfikować działanie systemu w praktyce ("Proof of Concept")

W trakcie prac okazało się, że specyfika Foundation Modelu wymaga znacznie głębszego zejścia w techniczne detale architektury niż zakładałem. Mimo poprawnego przygotowania ogólnego, moje założenia dotyczące formatu danych wejściowych (embeddingów) wymagały rewizji. Model, oparty na zaawansowanym mechanizmie uwagi (attention), przetwarzał dane w sposób kontekstowy (całe wycinki obrazu), a nie punktowy, co odkryłem dzięki wnikliwej analizie zachowania systemu.

To doświadczenie było kluczową lekcją, która pozwoliła mi zrozumieć różnicę między badaniami ogólnymi a deep-tech wymaganymi przy pracy z technologiami klasy "cutting-edge". Czas poświęcony na refaktoryzację kodu nie był stracony – pozwolił mi na dogłębne zrozumienie architektury Transformerów w danych geoprzestrzennych, co jest unikalną kompetencją na rynku. Wyciągnięte wnioski natychmiast przekułem w sukces w kolejnym projekcie konkursowym (realizowanym w ramach programu dużej firmy technologicznej), gdzie jako zespół z koła naukowego zajęliśmy miejsce na podium. Tam, bogatszy o doświadczenie, od razu przygotowałem precyzyjny Low-Level Design, co pozwoliło na bezbłędną i efektywną implementację.

## Wnioski

- **Specyfika nowych technologii**: Przy wdrażaniu rozwiązań, z którymi stykamy się po raz pierwszy (jak Foundation Models), standardowy research może być niewystarczający. Należy uwzględnić dodatkowy czas na tzw. "deep dive" techniczny, czyli analizę architektury rozwiązania na najniższym poziomie (Low-Level Design)
- **Jakość vs. Ilość informacji**: Solidny research to nie tylko zgromadzenie dużej ilości materiałów, ale przede wszystkim ich techniczna weryfikacja pod kątem konkretnego zastosowania (Use Case). Tworzenie tabel porównawczych z parametrami technicznymi (np. format tensorów wejściowych, wymagania pamięciowe) pozwala uniknąć pułapek implementacyjnych.
- **Ewolucyjne podejście do projektu**: Konieczność zmiany podejścia w trakcie projektu nie jest porażką, lecz naturalnym elementem pracy badawczo-rozwojowej (R&D). Kluczem do sukcesu jest szybka identyfikacja rozbieżności i adaptacja planu, co w moim przypadku doprowadziło do głębszego zrozumienia technologii.
- **Dokumentacja jako narzędzie analityczne**: Tworzenie dokumentacji technicznej i schematów przepływu danych (Data Flow Diagrams) przed rozpoczęciem kodowania pozwala zweryfikować poprawność założeń i jest kluczowe w projektach o wysokim stopniu skomplikowania.
- **Weryfikacja poprzez eksperyment**: Najlepszym uzupełnieniem teoretycznego researchu są szybkie eksperymenty na małej skali. Pozwalają one potwierdzić, czy nasze rozumienie dokumentacji pokrywa się z rzeczywistym działaniem bibliotek i modeli.
